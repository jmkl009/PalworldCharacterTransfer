import pickle
import os
from sys import exit

from tkinter import *
from tkinter.filedialog import askopenfilename
from tkinter import ttk, messagebox
from lib.palsav import compress_gvas_to_sav, decompress_sav_to_gvas
from lib.paltypes import PALWORLD_CUSTOM_PROPERTIES, PALWORLD_TYPE_HINTS
from lib.gvas import GvasHeader, GvasFile
from lib.archive import *
from typing import Any, Callable
import io
import struct
from typing import Sequence
from time import time
import threading

STRUCT_START = b'\x0f\x00\x00\x00StructProperty\x00'
MAP_START = b'\x0c\x00\x00\x00MapProperty\x00'
ARRAY_START = b'\x0e\x00\x00\x00ArrayProperty\x00'


def _convert_stringval(value):
    """Converts a value to, hopefully, a more appropriate Python object."""
    if hasattr(value, 'typename'):
        value = str(value)
        try:
            value = int(value)
        except (ValueError, TypeError):
            pass
    return value


ttk._convert_stringval = _convert_stringval


class SkipFArchiveWriter(FArchiveWriter):
    data: io.BytesIO
    size: int
    custom_properties: dict[str, tuple[Callable, Callable]]
    debug: bool

    def __init__(
            self,
            custom_properties: dict[str, tuple[Callable, Callable]] = {},
            debug: bool = os.environ.get("DEBUG", "0") == "1",
    ):
        self.data = io.BytesIO()
        self.custom_properties = custom_properties
        self.debug = debug

    def curr_properties(self, properties):
        for key in properties:
            if key not in ['custom_type', 'skip_type']:
                self.fstring(key)
                self.property(properties[key])

    def properties(self, properties: dict[str, Any]):
        for key in properties:
            if key not in ['custom_type', 'skip_type']:
                self.fstring(key)
                self.property(properties[key])
        self.fstring("None")

    def copy(self) -> "SkipFArchiveWriter":
        return SkipFArchiveWriter(self.custom_properties)

    def write_sections(self, props, section_ranges, bytes, parent_section_size_idx):
        props = [{k: v} for k, v in props.items()]
        prop_bytes = []
        for prop in props:
            self.curr_properties(prop)
            prop_bytes.append(self.bytes())
            self.data = io.BytesIO()
        bytes_concat_array = []
        last_end = 0
        n_bytes_more = 0
        old_size = struct.unpack('Q', bytes[parent_section_size_idx:parent_section_size_idx + 8])[0]
        for prop_byte, (section_start, section_end) in zip(prop_bytes, section_ranges):
            bytes_concat_array.append(bytes[last_end:section_start])
            bytes_concat_array.append(prop_byte)
            n_bytes_more += len(prop_byte) - (section_end - section_start)
            last_end = section_end
        bytes_concat_array.append(bytes[last_end:])
        new_size_bytes = struct.pack('Q', old_size + n_bytes_more)
        # parent section should always be the first
        bytes_concat_array[0] = bytes_concat_array[0][:parent_section_size_idx] + new_size_bytes + bytes_concat_array[
                                                                                                       0][
                                                                                                   parent_section_size_idx + 8:]
        output = b''
        for byte_segment in bytes_concat_array:
            output += byte_segment

        return output


    def guid(self, u): # Does not instantiate UUID class
        self.data.write(u)


    def optional_guid(self, u): # Does not instantiate UUID class
        if u is None:
            self.bool(False)
        else:
            self.bool(True)
            self.data.write(u)


class SkipFArchiveReader(FArchiveReader):

    def __init__(
            self,
            data,
            type_hints: dict[str, str] = {},
            custom_properties: dict[str, tuple[Callable, Callable]] = {},
            debug=False,
            allow_nan=True
    ):
        self.size = len(data)
        self.orig_data = data
        self.data = io.BytesIO(data)
        self.type_hints = type_hints
        self.debug = debug
        self.custom_properties = custom_properties
        self.allow_nan = allow_nan

    def curr_property(self, path: str = "") -> dict[str, Any]:
        properties = {}
        name = self.fstring()
        type_name = self.fstring()
        size = self.u64()
        properties[name] = self.property(type_name, size, f"{path}.{name}")
        return properties

    def internal_copy(self, data, debug: bool) -> "FArchiveReader":
        return SkipFArchiveReader(
            data,
            self.type_hints,
            self.custom_properties,
            debug=debug,
            allow_nan=self.allow_nan,
        )

    def skip(self, size: int) -> None:
        self.data.seek(size, 1)

    def properties_until_end(self, path: str = "") -> dict[str, Any]:
        properties = {}
        while True:
            name = self.fstring()
            if name == "None":
                break
            type_name = self.fstring()
            size = self.u64()
            # print(name, path)
            properties[name] = self.property(type_name, size, f"{path}.{name}")
        return properties

    def guid(self):
        # in the hot loop, avoid function calls
        return self.data.read(16)

    def optional_guid(self):
        # in the hot loop, avoid function calls
        if self.data.read(1)[0]:
            return self.data.read(16)
        return None

    def encode(self, property_name):
        return struct.pack('i', len(property_name) + 1) + property_name.encode('ascii') + b'\x00'

    def find_property_start(self, property_name, type_start=STRUCT_START, offset=0, reverse=False):
        if not reverse:
            return self.orig_data[offset:].find(self.encode(property_name) + type_start) + offset
        return self.orig_data[offset:].rfind(self.encode(property_name) + type_start) + offset

    def load_section(self, property_name, type_start=STRUCT_START, path='.worldSaveData', reverse=False):
        find_timer = time()
        start_index = self.find_property_start(property_name, type_start, reverse=reverse)
        self.data.seek(start_index, 0)
        start_timer = time()
        prop = self.curr_property(path=path)
        end_timer = time()
        print(f"Property {property_name} loaded in {end_timer - start_timer} seconds, total time including find: {end_timer - find_timer}")
        return prop, (start_index, self.data.tell())

    def load_sections(self, prop_types, path='.worldSaveData', reverse=False):
        properties = {}
        end_idx = 0
        section_ranges = []
        for prop, type_start in prop_types:
            find_timer = time()
            start_idx = self.find_property_start(prop, type_start, offset=end_idx, reverse=reverse)
            if start_idx == end_idx - 1:
                raise ValueError(f"Property {prop} not found")
            self.data.seek(start_idx, 0)
            start_timer = time()
            properties.update(self.curr_property(path=path))
            end_timer = time()
            end_idx = self.data.tell()
            print(f"Property {prop} loaded in {end_timer - start_timer} seconds, total time including find: {end_timer - find_timer}")
            section_ranges.append((start_idx, end_idx))
        return properties, section_ranges


def skip_decode(
        reader: SkipFArchiveReader, type_name: str, size: int, path: str
) -> dict[str, Any]:
    if type_name == "ArrayProperty":
        array_type = reader.fstring()
        value = {
            "skip_type": type_name,
            "array_type": array_type,
            "id": reader.optional_guid(),
            "value": reader.read(size),
            "size": size
        }
    elif type_name == "MapProperty":
        key_type = reader.fstring()
        value_type = reader.fstring()
        _id = reader.optional_guid()
        value = {
            "skip_type": type_name,
            "key_type": key_type,
            "value_type": value_type,
            "id": _id,
            "value": reader.read(size),
        }
    elif type_name == "StructProperty":
        value = {
            "skip_type": type_name,
            "struct_type": reader.fstring(),
            "struct_id": reader.guid(),
            "id": reader.optional_guid(),
            "value": reader.read(size),
        }
    else:
        raise Exception(
            f"Expected ArrayProperty or MapProperty or StructProperty, got {type_name} in {path}"
        )
    return value


def skip_encode(
        writer: FArchiveWriter, property_type: str, properties: dict[str, Any]
) -> int:
    if "skip_type" not in properties:
        if properties['custom_type'] in PALWORLD_CUSTOM_PROPERTIES is not None:
            return PALWORLD_CUSTOM_PROPERTIES[properties["custom_type"]][1](
                writer, property_type, properties
            )
    if property_type == "ArrayProperty":
        # del properties["custom_type"]
        # del properties["skip_type"]
        writer.fstring(properties["array_type"])
        writer.optional_guid(properties.get("id", None))
        writer.write(properties["value"])
        return len(properties["value"])
    elif property_type == "MapProperty":
        # del properties["custom_type"]
        # del properties["skip_type"]
        writer.fstring(properties["key_type"])
        writer.fstring(properties["value_type"])
        writer.optional_guid(properties.get("id", None))
        writer.write(properties["value"])
        return len(properties["value"])
    elif property_type == "StructProperty":
        # del properties["custom_type"]
        # del properties["skip_type"]
        writer.fstring(properties["struct_type"])
        writer.guid(properties["struct_id"])
        writer.optional_guid(properties.get("id", None))
        writer.write(properties["value"])
        return len(properties["value"])
    else:
        raise Exception(
            f"Expected ArrayProperty or MapProperty or StructProperty, got {property_type}"
        )


def decode_group(
        reader: SkipFArchiveReader, type_name: str, size: int, path: str
) -> dict[str, Any]:
    if type_name != "MapProperty":
        raise Exception(f"Expected MapProperty, got {type_name}")
    value = reader.property(type_name, size, path, nested_caller_path=path)
    # Decode the raw bytes and replace the raw data
    group_map = value["value"]
    for group in group_map:
        group_type = group["value"]["GroupType"]["value"]["value"]
        if group_type == "EPalGroupType::Guild":
            group_bytes = group["value"]["RawData"]["value"]
            group["value"]["RawData"]["value"] = decode_bytes(
                reader, group_bytes, group_type
            )
    return value

def instance_id_reader(reader):
    return {
        "guid": reader.guid(),
        "instance_id": reader.guid(),
    }


def decode_bytes(
        parent_reader: SkipFArchiveReader, group_bytes: Sequence[int], group_type: str
) -> dict[str, Any]:
    reader = parent_reader.internal_copy(group_bytes, debug=False)
    reader.skip(4)  # Number of bytes skipped.
    group_data = {
        "group_type": group_type,
        "group_id": reader.guid(),
        "group_name": reader.fstring(),
        "individual_character_handle_ids": reader.tarray(instance_id_reader),
    }
    org = {
        "org_type": reader.byte(),
        "base_ids": reader.tarray(uuid_reader),
    }
    group_data |= org
    guild: dict[str, Any] = {
        "base_camp_level": reader.i32(),
        "map_object_instance_ids_base_camp_points": reader.tarray(uuid_reader),
        "guild_name": reader.fstring(),
    }
    group_data |= guild
    guild = {
        "admin_player_uid": reader.guid(),
        "players": [],
    }
    player_count = reader.i32()
    for _ in range(player_count):
        player = {
            "player_uid": reader.guid(),
            "player_info": {
                "last_online_real_time": reader.i64(),
                "player_name": reader.fstring(),
            },
        }
        guild["players"].append(player)
    group_data |= guild
    if not reader.eof():
        raise Exception("Warning: EOF not reached")
    return group_data


def encode_group(
        writer: FArchiveWriter, property_type: str, properties: dict[str, Any]
) -> int:
    if property_type != "MapProperty":
        raise Exception(f"Expected MapProperty, got {property_type}")
    custom_type = properties["custom_type"]
    del properties["custom_type"]
    group_map = properties["value"]
    encoded_list = []
    for i, group in enumerate(group_map):
        group_type = group["value"]["GroupType"]["value"]["value"]
        if group_type == "EPalGroupType::Guild":
            encoded_list.append((i, group["value"]["RawData"]["value"]))
            group["value"]["RawData"]["value"] = encode_bytes(group["value"]["RawData"]["value"])
    write_ret = writer.property_inner(property_type, properties)
    properties["custom_type"] = custom_type
    for i, orig_val in encoded_list:
        group_map[i]["value"]["RawData"]["value"] = orig_val
    return write_ret


def instance_id_writer(writer, d):
    writer.guid(d["guid"])
    writer.guid(d["instance_id"])

def encode_bytes(p: dict[str, Any]) -> bytes:
    outer_writer = SkipFArchiveWriter()
    writer = SkipFArchiveWriter()
    writer.guid(p["group_id"])
    writer.fstring(p["group_name"])
    writer.tarray(instance_id_writer, p["individual_character_handle_ids"])
    writer.byte(p["org_type"])
    writer.tarray(uuid_writer, p["base_ids"])
    writer.i32(p["base_camp_level"])
    writer.tarray(uuid_writer, p["map_object_instance_ids_base_camp_points"])
    writer.fstring(p["guild_name"])
    writer.guid(p["admin_player_uid"])
    writer.i32(len(p["players"]))
    for i in range(len(p["players"])):
        writer.guid(p["players"][i]["player_uid"])
        writer.i64(p["players"][i]["player_info"]["last_online_real_time"])
        writer.fstring(p["players"][i]["player_info"]["player_name"])
    encoded_bytes = writer.bytes()
    outer_writer.u32(len(encoded_bytes))
    outer_writer.write(encoded_bytes)
    return outer_writer.bytes()


PALWORLD_CUSTOM_PROPERTIES[".worldSaveData.CharacterSaveParameterMap.Value.RawData"] = (skip_decode, skip_encode)
PALWORLD_CUSTOM_PROPERTIES[".worldSaveData.DynamicItemSaveData.DynamicItemSaveData.RawData"] = (
    skip_decode, skip_encode)
PALWORLD_CUSTOM_PROPERTIES[".worldSaveData.DynamicItemSaveData.DynamicItemSaveData.ID"] = (skip_decode, skip_encode)
PALWORLD_CUSTOM_PROPERTIES[".worldSaveData.CharacterContainerSaveData.Value.Slots"] = (skip_decode, skip_encode)
PALWORLD_CUSTOM_PROPERTIES[".worldSaveData.CharacterContainerSaveData.Value.RawData"] = (skip_decode, skip_encode)
PALWORLD_CUSTOM_PROPERTIES[".worldSaveData.ItemContainerSaveData.Value.BelongInfo"] = (skip_decode, skip_encode)
PALWORLD_CUSTOM_PROPERTIES[".worldSaveData.ItemContainerSaveData.Value.Slots"] = (skip_decode, skip_encode)
PALWORLD_CUSTOM_PROPERTIES[".worldSaveData.ItemContainerSaveData.Value.RawData"] = (skip_decode, skip_encode)

PALWORLD_CUSTOM_PROPERTIES[".worldSaveData.GroupSaveDataMap"] = (decode_group, encode_group)
PALWORLD_CUSTOM_PROPERTIES[".worldSaveData.GroupSaveDataMap.Value.RawData"] = (skip_decode, skip_encode)

OwnerPlayerUIdSearchPrefix = b'\x0f\x00\x00\x00OwnerPlayerUId\x00\x0f\x00\x00\x00StructProperty\x00\x10\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00Guid\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
LocalIdSearchPrefix = b'\x16\x00\x00\x00LocalIdInCreatedWorld\x00\x0f\x00\x00\x00StructProperty\x00\x10\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00Guid\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
PalSlotDataPrefix = b'\r\x00\x00\x00ByteProperty\x00\x00!\x00\x00\x00'
OldOwnerPlayerUIdPrefix = b'\x13\x00\x00\x00OldOwnerPlayerUIds\x00\x0e\x00\x00\x00ArrayProperty\x00'
OldOwnerPlayerUIdSuffix = b'\x06\x00\x00\x00MaxHP'


def find_id_match_prefix(encoded_bytes, prefix):
    start_idx = encoded_bytes.find(prefix) + len(prefix)
    return encoded_bytes[start_idx:start_idx + 16]


def find_all_ids_match_prefix(encoded_bytes, prefix):
    last_idx = 0
    start_idx = encoded_bytes.find(prefix)
    ids = []
    while start_idx != last_idx - 1:
        start_idx += len(prefix)
        last_idx = start_idx + 16
        ids.append(encoded_bytes[start_idx:last_idx])
        start_idx = encoded_bytes[last_idx:].find(prefix) + last_idx
    return ids


def find_all_occurrences_with_prefix(encoded_bytes, prefix):
    last_idx = 0
    start_idx = encoded_bytes.find(prefix)
    end_indices = []
    while start_idx != last_idx - 1:
        start_idx += len(prefix)
        last_idx = start_idx
        end_indices.append(start_idx)
        start_idx = encoded_bytes[last_idx:].find(prefix) + last_idx
    return end_indices


def fast_deepcopy(json_dict):
    return pickle.loads(pickle.dumps(json_dict, -1))


class SkipGvasFile(GvasFile):
    header: GvasHeader
    properties: dict[str, Any]
    trailer: bytes

    @staticmethod
    def read(
        data: bytes,
        type_hints: dict[str, str] = {},
        custom_properties: dict[str, tuple[Callable, Callable]] = {},
        allow_nan: bool = True,
    ) -> "GvasFile":
        gvas_file = SkipGvasFile()
        with SkipFArchiveReader(
            data,
            type_hints=type_hints,
            custom_properties=custom_properties,
            allow_nan=allow_nan,
        ) as reader:
            gvas_file.header = GvasHeader.read(reader)
            gvas_file.properties = reader.properties_until_end()
            gvas_file.trailer = reader.read_to_end()
            if gvas_file.trailer != b"\x00\x00\x00\x00":
                print(
                    f"{len(gvas_file.trailer)} bytes of trailer data, file may not have fully parsed"
                )
        return gvas_file

    def write(
        self, custom_properties: dict[str, tuple[Callable, Callable]] = {}
    ) -> bytes:
        writer = SkipFArchiveWriter(custom_properties)
        self.header.write(writer)
        writer.properties(self.properties)
        writer.write(self.trailer)
        return writer.bytes()

def main():
    global host_sav_path, level_sav_path, t_level_sav_path, t_host_sav_path, host_json, level_json, targ_json, targ_lvl

    if None in [level_sav_path, t_level_sav_path, selected_source_player, selected_target_player]:
        messagebox.showerror(message='Please have both level files and players selected before starting transfer.')
        return

    # Warn the user about potential data loss.
    response = messagebox.askyesno(title='WARNING', message='WARNING: Running this script WILL change your target save files and could \
potentially corrupt your data. It is HIGHLY recommended that you make a backup \
of your save folder before continuing. Press Yes if you would like to continue.')
    if not response:
        return

    host_json_gvas = load_player_file(level_sav_path, selected_source_player)
    if host_json_gvas is None:
        return
    host_json = host_json_gvas.properties
    targ_json_gvas = load_player_file(t_level_sav_path, selected_target_player)
    if targ_json_gvas is None:
        return
    targ_json = targ_json_gvas.properties

    host_guid = UUID.from_str(selected_source_player).raw_bytes

    host_instance_id = host_json["SaveData"]["value"]["IndividualId"]["value"]["InstanceId"]["value"]
    pal_player_uid_filters = [b'\x00'*16, b'\x00'*12 + b'\x01\x00\x00\x00'] # Plyaer ID 000..00 and 000...01
    count = 0
    found = 0
    expected_containers = 7
    exported_map = {}
    param_maps = []
    palcount = 0
    for character_save_param in level_json["CharacterSaveParameterMap"]["value"]:
        instance_id = character_save_param["key"]["InstanceId"]["value"]
        if instance_id == host_instance_id:
            exported_map = character_save_param
            count = count + 1
            found = 1
            print('found instance')
        elif character_save_param["key"]["PlayerUId"]["value"] in pal_player_uid_filters:
            if find_id_match_prefix(character_save_param['value']['RawData']['value'],
                                    OwnerPlayerUIdSearchPrefix) == host_guid:
                param_maps.append(fast_deepcopy(character_save_param))
                palcount += 1

    if not found:
        print("Couldn't find character instance data to export")
        messagebox.showerror(message="Couldn't find source character instance data in the source world save")
        return
    print("Found Character Parameter Map")
    print(f"Read {palcount} pals from source save")

    print("Searching for container data")
    host_save = host_json["SaveData"]["value"]
    inv_info = host_save["InventoryInfo"]["value"] if "InventoryInfo" in host_save else host_save["inventoryInfo"]["value"]
    inv_main = inv_info["CommonContainerId"]
    inv_key = inv_info["EssentialContainerId"]
    inv_weps = inv_info["WeaponLoadOutContainerId"]
    inv_armor = inv_info["PlayerEquipArmorContainerId"]
    inv_foodbag = inv_info["FoodEquipContainerId"]
    inv_pals = host_json["SaveData"]["value"]["PalStorageContainerId"]
    inv_otomo = host_json["SaveData"]["value"]["OtomoCharacterContainerId"]

    host_main = {}
    host_key = {}
    host_weps = {}
    host_armor = {}
    host_foodbag = {}
    host_pals = {}
    host_otomo = {}
    count = 0

    for container in level_json["CharacterContainerSaveData"]["value"]:
        container_id = container["key"]["ID"]["value"]
        if container_id == inv_pals["value"]["ID"]["value"]:
            print("Found host pal inventory")
            host_pals = container
            count = count + 1
        elif container_id == inv_otomo["value"]["ID"]["value"]:
            print("Found host otomo inventory")
            host_otomo = container
            count = count + 1
        if count >= 2:
            print("Found all pal containers")
            break

    dynamic_guids = set()
    for container in level_json["ItemContainerSaveData"]["value"]:
        container_id = container["key"]["ID"]["value"]
        if container_id == inv_main["value"]["ID"]["value"]:
            print("Found host main inventory")
            dynamic_guids |= set(find_all_ids_match_prefix(container['value']['Slots']['value'], LocalIdSearchPrefix))
            host_main = container
            count = count + 1
        elif container_id == inv_key["value"]["ID"]["value"]:
            print("Found host key inventory")
            # Potentially do not need the following line as there might not be a dyanmic key item
            dynamic_guids |= set(find_all_ids_match_prefix(container['value']['Slots']['value'], LocalIdSearchPrefix))
            host_key = container
            count = count + 1
        elif container_id == inv_weps["value"]["ID"]["value"]:
            print("Found host weapon inventory")
            dynamic_guids |= set(find_all_ids_match_prefix(container['value']['Slots']['value'], LocalIdSearchPrefix))
            host_weps = container
            count = count + 1
        elif container_id == inv_armor["value"]["ID"]["value"]:
            print("Found host armor inventory")
            dynamic_guids |= set(find_all_ids_match_prefix(container['value']['Slots']['value'], LocalIdSearchPrefix))
            host_armor = container
            count = count + 1
        elif container_id == inv_foodbag["value"]["ID"]["value"]:
            print("Found host food bag inventory")
            dynamic_guids |= set(find_all_ids_match_prefix(container['value']['Slots']['value'], LocalIdSearchPrefix))
            host_foodbag = container
            count = count + 1
        if count >= expected_containers:
            print("Found all target containers")
            break
    dynamic_guids.remove(b'\x00' * 16)

    dynamic_container_level_json = level_json['DynamicItemSaveData']['value']['values']
    level_additional_dynamic_containers = []
    for dynamic_container in dynamic_container_level_json:
        LocalIdInCreatedWorld = find_id_match_prefix(dynamic_container['ID']['value'], LocalIdSearchPrefix)
        if LocalIdInCreatedWorld in dynamic_guids:
            level_additional_dynamic_containers.append((dynamic_container, LocalIdInCreatedWorld))

    if count < expected_containers:
        print("Missing container info! Only found " + str(count))
        messagebox.showerror(message="Missing container info! Only found " + str(count))
        return

    char_instanceid = targ_json["SaveData"]["value"]["IndividualId"]["value"]["InstanceId"]["value"]

    print("Transferring profile data...")
    if "TechnologyPoint" in host_json["SaveData"]["value"]:
        targ_json["SaveData"]["value"]["TechnologyPoint"] = host_json["SaveData"]["value"]["TechnologyPoint"]
    elif "TechnologyPoint" in targ_json["SaveData"]["value"]:
        targ_json["SaveData"]["value"]["TechnologyPoint"]["value"] = 0

    if "bossTechnologyPoint" in host_json["SaveData"]["value"]:
        targ_json["SaveData"]["value"]["bossTechnologyPoint"] = host_json["SaveData"]["value"]["bossTechnologyPoint"]
    elif "bossTechnologyPoint" in targ_json["SaveData"]["value"]:
        targ_json["SaveData"]["value"]["bossTechnologyPoint"]["value"] = 0
    targ_json["SaveData"]["value"]["UnlockedRecipeTechnologyNames"] = host_json["SaveData"]["value"][
        "UnlockedRecipeTechnologyNames"]
    targ_json["SaveData"]["value"]["PlayerCharacterMakeData"] = host_json["SaveData"]["value"][
            "PlayerCharacterMakeData"]
    if 'RecordData' in host_json["SaveData"]["value"]:
        targ_json["SaveData"]["value"]["RecordData"] = host_json["SaveData"]["value"]["RecordData"]
    elif 'RecordData' in targ_json["SaveData"]:
        del targ_json['RecordData']

    target_section_load_handle.join()
    found = False
    for i, char_save_instance in enumerate(targ_lvl["CharacterSaveParameterMap"]["value"]):
        instance_id = char_save_instance["key"]["InstanceId"]["value"]
        if instance_id == char_instanceid:
            print("Existing character parameter map found, overwriting")
            char_save_instance['value'] = exported_map['value']
            found = True
            break
    if not found:
        print("Couldn't find character paramater map, aborting")
        messagebox.showerror(message="Couldn't find target character instance in target world save.")
        return

    print("Searching for target containers")

    targ_save = targ_json["SaveData"]["value"]
    inv_info = targ_save["InventoryInfo"]["value"] if "InventoryInfo" in targ_save else targ_save["inventoryInfo"]["value"]
    inv_main = inv_info["CommonContainerId"]
    inv_key = inv_info["EssentialContainerId"]
    inv_weps = inv_info["WeaponLoadOutContainerId"]
    inv_armor = inv_info["PlayerEquipArmorContainerId"]
    inv_foodbag = inv_info["FoodEquipContainerId"]

    host_inv_pals = inv_pals
    host_inv_otomo = inv_otomo
    inv_pals = targ_json["SaveData"]["value"]["PalStorageContainerId"]
    inv_otomo = targ_json["SaveData"]["value"]["OtomoCharacterContainerId"]

    group_id = None
    targ_uid = targ_json["SaveData"]["value"]["IndividualId"]["value"]["PlayerUId"]["value"]
    if not keep_old_guild_id:
        for group_data in targ_lvl["GroupSaveDataMap"]["value"]:
            if group_data["value"]["GroupType"]["value"]["value"] == "EPalGroupType::Guild":
                if targ_uid in [player_item['player_uid'] for player_item in
                                group_data["value"]["RawData"]["value"]["players"]]:
                    group_id = group_data["value"]["RawData"]["value"]['group_id']
                    guild_items_json = group_data["value"]["RawData"]["value"]["individual_character_handle_ids"]
                    break

        if group_id is None:
            messagebox.showerror(message='Guild ID not found, aboorting')
            return
        guild_item_instances = set()
        for guild_item in guild_items_json:
            guild_item_instances.add(guild_item['instance_id'])
    else:
        # Remove guild with new character in it
        for group_idx, group_data in enumerate(targ_lvl["GroupSaveDataMap"]["value"]):
            if group_data["value"]["GroupType"]["value"]["value"] == "EPalGroupType::Guild" and group_data["key"] not in source_guild_dict:
                new_character_guild_found = False
                for player_idx, player_item in enumerate(group_data["value"]["RawData"]["value"]["players"]):
                    if player_item['player_uid'] == targ_uid:
                        new_character_guild_found = True
                        break
                if new_character_guild_found:
                    group_data["value"]["RawData"]["value"]["players"].pop(player_idx)
                    if len(group_data["value"]["RawData"]["value"]["players"]) > 0: # There are still people in this guild
                        if group_data["value"]["RawData"]["value"]["admin_player_uid"] == targ_uid: # give admin to the next player
                            group_data["value"]["RawData"]["value"]["admin_player_uid"] = group_data["value"]["RawData"]["value"]["players"][0]['player_uid']
                        for handle_idx, character_handle_id in enumerate(group_data["value"]["RawData"]["value"]["individual_character_handle_ids"]):
                            if character_handle_id['guid'] == targ_uid:
                                group_data["value"]["RawData"]["value"]["individual_character_handle_ids"].pop(handle_idx)
                    else: # remove the guild entirely if no player is in the guild anymore
                        targ_lvl["GroupSaveDataMap"]["value"].pop(group_idx)
                    break

        for group_data in targ_lvl["GroupSaveDataMap"]["value"]:
            if group_data["key"] in source_guild_dict:
                old_player_found = False
                for player_item in group_data["value"]["RawData"]["value"]["players"]:
                    if player_item['player_uid'] == host_guid:
                        old_player_found = True
                        player_item['player_uid'] = targ_uid
                        break
                if old_player_found:
                    for character_handle_id in group_data["value"]["RawData"]["value"]["individual_character_handle_ids"]:
                        if character_handle_id['guid'] == host_guid:
                            character_handle_id['guid'] = targ_uid
                            character_handle_id['instance_id'] = char_instanceid
                            break
                    if group_data["value"]["RawData"]["value"]["admin_player_uid"] == host_guid:
                        group_data["value"]["RawData"]["value"]["admin_player_uid"] = targ_uid
                    group_id = group_data["key"]
                    break
        if group_id is None: # No old guild containing the source player is found
            print("No old guild containing the source player is found in target, moving guilds from old world now...")
            old_guild = None
            for group_data in source_guild_dict.values():
                for player_item in group_data["value"]["RawData"]["value"]["players"]:
                    if player_item['player_uid'] == host_guid:
                        old_guild = fast_deepcopy(group_data)
                        break
            if old_guild is None:
                print("No guild containing the source player is found in the source either, either this is a bug or the files are corrupted. Aborting.")
                messagebox.showerror(message="No guild containing the source player is found in the source either, either this is a bug or the files are corrupted. Aborting.")
                return
            group_id = old_guild["key"]
            if old_guild["value"]["RawData"]["value"]["admin_player_uid"] == host_guid:
                old_guild["value"]["RawData"]["value"]["admin_player_uid"] = targ_uid
            for player_item in old_guild["value"]["RawData"]["value"]["players"]:
                if player_item['player_uid'] == host_guid:
                    player_item['player_uid'] = targ_uid
                    break
            for character_handle_id in old_guild["value"]["RawData"]["value"]["individual_character_handle_ids"]:
                if character_handle_id['guid'] == host_guid:
                    character_handle_id['guid'] = targ_uid
                    character_handle_id['instance_id'] = char_instanceid
                    break
            targ_lvl["GroupSaveDataMap"]["value"].append(old_guild)

    for pal_param in param_maps:
        pal_data = pal_param['value']['RawData']['value']
        slot_id_idx = pal_data.find(b'\x07\x00\x00\x00SlotID\x00\x0f\x00\x00\x00StructProperty\x00')
        if slot_id_idx == -1:
            continue
        pal_container_id_bytes = pal_data[slot_id_idx + 217:slot_id_idx + 233]
        pal_data_bytearray = bytearray(pal_data)
        if pal_container_id_bytes == host_inv_pals["value"]["ID"]["value"]:
            pal_data_bytearray[slot_id_idx + 217:slot_id_idx + 233] = inv_pals["value"]["ID"]["value"]
        elif pal_container_id_bytes == host_inv_otomo["value"]["ID"]["value"]:
            pal_data_bytearray[slot_id_idx + 217:slot_id_idx + 233] = inv_otomo["value"]["ID"]["value"]
        player_uid_start_idx = pal_data.find(OwnerPlayerUIdSearchPrefix) + len(OwnerPlayerUIdSearchPrefix)

        # old_owner_players_start = pal_data[player_uid_start_idx:].find(OldOwnerPlayerUIdPrefix) + player_uid_start_idx
        # old_owner_players_end = pal_data[old_owner_players_start:].find(
        #     OldOwnerPlayerUIdSuffix) + old_owner_players_start
        # old_owner_players = SkipFArchiveReader(pal_data[old_owner_players_start:old_owner_players_end]).curr_property()
        # old_owner_players['OldOwnerPlayerUIds']['value']['values'][-1] = targ_uid
        # tmp_writer = SkipFArchiveWriter()
        # tmp_writer.curr_properties(old_owner_players)
        # replace_bytes = tmp_writer.bytes()

        pal_data_bytearray[player_uid_start_idx:player_uid_start_idx + 16] = targ_uid
        # pal_data_bytearray[old_owner_players_start:old_owner_players_end] = replace_bytes
        pal_data_bytearray[-16:] = group_id

        pal_param['value']['RawData']['value'] = bytes(pal_data_bytearray)
        # print(UUID(pal_data[-16:]), UUID(pal_param['value']['RawData']['value'][-16:]))
        if not keep_old_guild_id and pal_param["key"]["InstanceId"]["value"] not in guild_item_instances:
            guild_items_json.append(
                {"guid": pal_param["key"]["PlayerUId"]["value"],
                 "instance_id": pal_param["key"]["InstanceId"]["value"]})

    new_character_save_param_map = []
    removed = 0
    for entity in targ_lvl["CharacterSaveParameterMap"]["value"]:
        if find_id_match_prefix(entity['value']['RawData']['value'], OwnerPlayerUIdSearchPrefix) == targ_uid:
            removed += 1
            continue
        new_character_save_param_map.append(entity)
    new_character_save_param_map += param_maps
    targ_lvl["CharacterSaveParameterMap"]["value"] = new_character_save_param_map
    print(f"Removed {removed} pals from the original character in the target world")
    print(f"Appended {len(param_maps)} pals of data from the source character")

    count = 0
    for container in targ_lvl["CharacterContainerSaveData"]["value"]:
        container_id = container["key"]["ID"]["value"]
        if container_id == inv_pals["value"]["ID"]["value"]:
            # print(container['value'])
            target_slot_data_starts = find_all_occurrences_with_prefix(container['value']['Slots']['value'],
                                                                       PalSlotDataPrefix)
            source_slot_data_starts = find_all_occurrences_with_prefix(host_pals['value']['Slots']['value'],
                                                                       PalSlotDataPrefix)
            target_slot_bytearray = bytearray(container['value']['Slots']['value'])
            source_slot_bytearray = bytearray(host_pals['value']['Slots']['value'])
            for target_start, source_start in zip(target_slot_data_starts, source_slot_data_starts):
                target_slot_bytearray[target_start:target_start + 33] = source_slot_bytearray[
                                                                        source_start:source_start + 33]
            container['value']['Slots']['value'] = bytes(target_slot_bytearray)
            count += 1
        elif container_id == inv_otomo["value"]["ID"]["value"]:
            target_slot_data_starts = find_all_occurrences_with_prefix(container['value']['Slots']['value'],
                                                                       PalSlotDataPrefix)
            source_slot_data_starts = find_all_occurrences_with_prefix(host_otomo['value']['Slots']['value'],
                                                                       PalSlotDataPrefix)
            target_slot_bytearray = bytearray(container['value']['Slots']['value'])
            source_slot_bytearray = bytearray(host_otomo['value']['Slots']['value'])
            for target_start, source_start in zip(target_slot_data_starts, source_slot_data_starts):
                target_slot_bytearray[target_start:target_start + 33] = source_slot_bytearray[
                                                                        source_start:source_start + 33]
            container['value']['Slots']['value'] = bytes(target_slot_bytearray)
            count += 1
        if count >= 2:
            print("Found all pal containers")
            break

    for container in targ_lvl["ItemContainerSaveData"]["value"]:
        container_id = container["key"]["ID"]["value"]
        if container_id == inv_main["value"]["ID"]["value"]:
            print("Found main inventory in target")
            container["value"] = host_main["value"]
            count += 1
        elif container_id == inv_key["value"]["ID"]["value"]:
            print("Found key inventory in target")
            container["value"] = host_key["value"]
            count += 1
        elif container_id == inv_weps["value"]["ID"]["value"]:
            print("Found weapon inventory in target")
            container["value"] = host_weps["value"]
            count += 1
        elif container_id == inv_armor["value"]["ID"]["value"]:
            print("Found armor inventory in target")
            container["value"] = host_armor["value"]
            count += 1
        elif container_id == inv_foodbag["value"]["ID"]["value"]:
            print("Found food bag inventory in target")
            container["value"] = host_foodbag["value"]
            count += 1
        if count >= expected_containers:
            print("Found all target containers")
            break

    target_dynamic_containers = targ_lvl['DynamicItemSaveData']['value']['values']
    repeated_indices = set()
    for i, target_dynamic_container in enumerate(target_dynamic_containers):
        target_guid = find_id_match_prefix(target_dynamic_container['ID']['value'], LocalIdSearchPrefix)
        if target_guid in dynamic_guids:
            for j, (dynamic_container, container_local_id) in enumerate(level_additional_dynamic_containers):
                if target_guid == container_local_id:
                    target_dynamic_containers[i] = dynamic_container
                    repeated_indices.add(j)
                    break
    targ_lvl['DynamicItemSaveData']['value']['values'] += [container for i, (container, local_id) in
                                                           enumerate(level_additional_dynamic_containers) if
                                                           i not in repeated_indices]
    print("Transferred all Dynamic containers, writing to output...")

    WORLDSAVESIZEPREFIX = b'\x0e\x00\x00\x00worldSaveData\x00\x0f\x00\x00\x00StructProperty\x00'
    size_idx = target_raw_gvas.find(WORLDSAVESIZEPREFIX) + len(WORLDSAVESIZEPREFIX)
    output_data = SkipFArchiveWriter(custom_properties=PALWORLD_CUSTOM_PROPERTIES).write_sections(targ_lvl,
                                                                                                  target_section_ranges,
                                                                                                  target_raw_gvas,
                                                                                                  size_idx)

    targ_json_gvas.properties = targ_json
    t_host_sav_path = os.path.join(os.path.dirname(t_level_sav_path), 'Players', selected_target_player + '.sav')
    if not os.path.exists(t_host_sav_path):
        t_host_sav_path = os.path.join(os.path.dirname(t_level_sav_path), '../Players', selected_target_player + '.sav')

    print("Writing to file...")
    gvas_to_sav(t_level_sav_path, output_data)
    gvas_to_sav(t_host_sav_path, targ_json_gvas.write())

    print("Saved all data successfully. PLEASE DON'T BREAK")
    messagebox.showinfo(
        message='Transfer finished! You may continue transferring more players or close the windows now.')


def sav_to_gvas(file):
    with open(file, 'rb') as f:
        data = f.read()
        raw_gvas, save_type, cnk_header = decompress_sav_to_gvas(data)
    return raw_gvas, save_type, cnk_header


def gvas_to_sav(file, gvas_data):
    sav_file_data = compress_gvas_to_sav(
        gvas_data, target_save_type, cnk_header=None if output_old_save_version else TARGET_CNK_DATA_HEADER
    )
    with open(file, 'wb') as out:
        out.write(sav_file_data)


def select_file():
    return askopenfilename(filetypes=[("Palworld Saves", "*.sav *.json")])


def ishex(s):
    try:
        int(s, 16)
        return True
    except ValueError:
        return False


def load_file(path):
    global status_label, root
    loaded_file, save_type, cnk_header = None, None, None
    if path.endswith(".sav"):
        loaded_file, save_type, cnk_header = sav_to_gvas(path)
        if cnk_header[8:11] == b"PlZ":
            cnk_header = None
    return loaded_file, save_type, cnk_header


def load_player_file(level_sav_path, player_uid):
    player_file_path = os.path.join(os.path.dirname(level_sav_path), 'Players', player_uid + '.sav')
    if not os.path.exists(player_file_path):
        player_file_path = os.path.join(os.path.dirname(level_sav_path), '../Players', player_uid + '.sav')
        if not os.path.exists(player_file_path):
            messagebox.showerror(message=f"Player file {player_file_path} not present")
            return None
    raw_gvas, _, _ = load_file(player_file_path)
    if not raw_gvas:
        messagebox.showerror(message=f"Invalid file {player_file_path}")
        return
    return SkipGvasFile.read(raw_gvas)


def load_players(save_json, is_source):
    guild_dict = source_guild_dict if is_source else target_guild_dict
    if len(guild_dict) > 0:
        guild_dict.clear()
    players = dict()
    for group_data in save_json["GroupSaveDataMap"]["value"]:
        if group_data["value"]["GroupType"]["value"]["value"] == "EPalGroupType::Guild":
            group_id = group_data["value"]["RawData"]["value"]['group_id']
            players[group_id] = group_data["value"]["RawData"]["value"]["players"]
            guild_dict[group_id] = group_data
    list_box = source_player_list if is_source else target_player_list
    for item in list_box.get_children():
        list_box.delete(item)
    for guild_id, player_items in players.items():
        for player_item in player_items:
            playerUId = ''.join(str(UUID(player_item['player_uid'])).split('-')).upper()
            list_box.insert('', END, values=(UUID(guild_id), playerUId, player_item['player_info']['player_name']))


def load_all_source_sections_async(group_save_section, reader):
    global level_json
    level_json, _ = reader.load_sections([
        ('CharacterSaveParameterMap', MAP_START),
        ('ItemContainerSaveData', MAP_START),
        ('DynamicItemSaveData', ARRAY_START),
        ('CharacterContainerSaveData', MAP_START)],
        path='.worldSaveData'
    )
    level_json.update(group_save_section)


def source_level_file():
    global level_sav_path, source_level_path_label, level_json, selected_source_player, source_section_load_handle
    tmp = select_file()
    if tmp:
        if not tmp.endswith('.sav'):
            messagebox.showerror("Incorrect file", "This is not the right file. Please select *.sav file.")
            return
        raw_gvas, _, _ = load_file(tmp)
        if not raw_gvas:
            messagebox.showerror(message="Invalid files, files must be .sav")
            return
        reader = SkipFArchiveReader(raw_gvas, PALWORLD_TYPE_HINTS, PALWORLD_CUSTOM_PROPERTIES)
        group_save_section, _ = reader.load_section('GroupSaveDataMap', MAP_START, reverse=True)
        source_section_load_handle = threading.Thread(target=load_all_source_sections_async, args=(group_save_section, reader))
        source_section_load_handle.start()
        load_players(group_save_section, True)
        source_level_path_label.config(text=tmp)
        level_sav_path = tmp
        selected_source_player = None
        current_selection_label.config(text=f"source: {selected_source_player}, target: {selected_target_player}")


def load_all_target_sections_async(group_save_section, group_save_section_range, reader):
    global targ_lvl, target_section_ranges
    targ_lvl, target_section_ranges = reader.load_sections([
        ('CharacterSaveParameterMap', MAP_START),
        ('ItemContainerSaveData', MAP_START),
        ('DynamicItemSaveData', ARRAY_START),
        ('CharacterContainerSaveData', MAP_START)],
        path='.worldSaveData'
    )
    targ_lvl.update(group_save_section)
    target_section_ranges.append(group_save_section_range)


def target_level_file():
    global t_level_sav_path, target_level_path_label, targ_lvl, target_level_cache, target_section_ranges, target_raw_gvas, target_save_type, selected_target_player, target_section_load_handle, TARGET_CNK_DATA_HEADER
    tmp = select_file()
    if tmp:
        if not tmp.endswith('.sav'):
            messagebox.showerror("Incorrect file", "This is not the right file. Please select *.sav file.")
            return
        raw_gvas, target_save_type, TARGET_CNK_DATA_HEADER = load_file(tmp)
        if not raw_gvas:
            messagebox.showerror(message="Invalid files, files must be .sav")
            return
        target_raw_gvas = raw_gvas
        reader = SkipFArchiveReader(raw_gvas, PALWORLD_TYPE_HINTS, PALWORLD_CUSTOM_PROPERTIES)
        group_save_section, group_save_section_range = reader.load_section('GroupSaveDataMap', MAP_START, reverse=True)
        target_section_load_handle = threading.Thread(target=load_all_target_sections_async, args=(group_save_section, group_save_section_range, reader))
        target_section_load_handle.start()
        load_players(group_save_section, False)
        target_level_path_label.config(text=tmp)
        t_level_sav_path = tmp
        selected_target_player = None
        current_selection_label.config(text=f"source: {selected_source_player}, target: {selected_target_player}")

def on_exit():
    global level_sav_path, host_sav_path, t_level_sav_path, t_host_sav_path
    print("Application is closing")
    root.destroy()  # Ensures the application window closes cleanly


def on_selection_of_source_player(event):
    global selected_source_player
    selections = source_player_list.selection()
    if len(selections):
        selected_source_player = source_player_list.item(selections[0])['values'][1]
        current_selection_label.config(text=f"source: {selected_source_player}, target: {selected_target_player}")


def on_selection_of_target_player(event):
    global selected_target_player
    selections = target_player_list.selection()
    if len(selections):
        selected_target_player = target_player_list.item(selections[0])['values'][1]
        current_selection_label.config(text=f"source: {selected_source_player}, target: {selected_target_player}")

def on_keep_old_guild_check():
    global keep_old_guild_id
    keep_old_guild_id = bool(checkbox_var.get())
    print("Keep old guild id after transfer:", "on" if keep_old_guild_id else "off")

def on_output_old_save_version_check():
    global output_old_save_version
    output_old_save_version = bool(save_version_var.get())
    print("Output Old Save Version:", "on" if output_old_save_version else "off")

level_sav_path, host_sav_path, t_level_sav_path, t_host_sav_path = None, None, None, None
level_json, host_json, targ_lvl, targ_json = None, None, None, None
target_section_ranges, target_save_type, target_raw_gvas, targ_json_gvas = None, None, None, None
selected_source_player, selected_target_player = None, None
keep_old_guild_id, output_old_save_version = False, False
TARGET_CNK_DATA_HEADER = None
source_guild_dict, target_guild_dict = dict(), dict()
source_section_load_handle, target_section_load_handle = None, None

# main()
root = Tk()
root.title(f"PalTransfer")
root.geometry("")
root.minsize("800", "300")

status_label = Label(root, text="Select files to transfer")
status_label.grid(row=0, column=0, columnspan=2, pady=20, sticky="ew")

root.columnconfigure(0, weight=3)
root.columnconfigure(1, weight=1)
root.rowconfigure(3, weight=1)
root.rowconfigure(5, weight=1)

Button(
    root,
    text='Select Source Level File',
    command=source_level_file
).grid(row=2, column=1, padx=10, pady=20, sticky="ew")
source_level_path_label = Label(root, text="...", wraplength=600)
source_level_path_label.grid(row=2, column=0, padx=10, pady=20, sticky="ew")

source_player_list = ttk.Treeview(root, columns=(0, 1, 2), show='headings')
source_player_list.grid(row=3, column=0, columnspan=2, padx=10, pady=10, sticky='nsew')

# Define the column headings
source_player_list.heading(0, text='Guild ID')
source_player_list.heading(1, text='Player ID')
source_player_list.heading(2, text='NickName')

source_player_list.column(0, width=100)
source_player_list.column(1, width=100)
source_player_list.column(2, width=100)

source_player_list.bind('<<TreeviewSelect>>', on_selection_of_source_player)

Button(
    root,
    text='Select Target Level File',
    command=target_level_file
).grid(row=4, column=1, padx=10, pady=20, sticky="ew")
target_level_path_label = Label(root, text="...", wraplength=600)
target_level_path_label.grid(row=4, column=0, padx=10, pady=20, sticky="ew")

target_player_list = ttk.Treeview(root, columns=(0, 1, 2), show='headings')
target_player_list.grid(row=5, column=0, columnspan=2, padx=10, pady=10, sticky='nsew')

# Define the column headings
target_player_list.heading(0, text='Guild ID')
target_player_list.heading(1, text='Player ID')
target_player_list.heading(2, text='NickName')

target_player_list.column(0, width=100)
target_player_list.column(1, width=100)
target_player_list.column(2, width=100)

target_player_list.bind('<<TreeviewSelect>>', on_selection_of_target_player)

current_selection_label = Label(root, text=f"source: {selected_source_player}, target: {selected_target_player}",
                                wraplength=600)
current_selection_label.grid(row=6, column=0, padx=10, pady=20, sticky="ew")

Button(
    root,
    text='Start Transfer!',
    command=main
).grid(row=6, column=1, columnspan=2, pady=20, sticky="ew")

checkbox_var = IntVar()
keep_old_guild_check = Checkbutton(root, text="Keep Old Guild ID After Transfer", variable=checkbox_var, command=on_keep_old_guild_check)
keep_old_guild_check.grid(row=7, column=0, columnspan=2, sticky='w', padx=10, pady=5)

save_version_var = IntVar()
keep_old_guild_check = Checkbutton(root, text="Output Old Save Version", variable=save_version_var, command=on_output_old_save_version_check)
keep_old_guild_check.grid(row=7, column=1, columnspan=2, sticky='w', padx=10, pady=5)


# Register the exit function
root.protocol("WM_DELETE_WINDOW", on_exit)

root.mainloop()
